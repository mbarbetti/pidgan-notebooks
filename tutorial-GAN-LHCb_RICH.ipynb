{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcVGQpi5i5xG"
      },
      "source": [
        "# Parameterizing the LHCb RICH system using the pidgan's `GAN` algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0R3STZPi5xJ"
      },
      "source": [
        "**Author:** [mbarbetti](https://github.com/mbarbetti)\n",
        "\n",
        "**Date created:** 12/10/2023\n",
        "\n",
        "**Last modified:** 12/10/2023\n",
        "\n",
        "**Description:** This tutorial demonstrates how to parameterize the high-level response of the LHCb RICH system using a Generative Adversarial Network (GAN) [[1](https://arxiv.org/abs/1406.2661)]. The code is written using the [pidgan](https://github.com/mbarbetti/pidgan) package that relies on TensorFlow and Keras as backends."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvTVEAa7i5xJ"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opu773xWi5xK"
      },
      "source": [
        "### What is LHCb?\n",
        "\n",
        "The [**LHCb experiment**](https://lhcb-outreach.web.cern.ch) has been originally designed to study rare decays of particles containing $b$ and $c$ quarks produced at the Large Hadron Collider (LHC). The LHCb detector, shown in the background of the following photo, is a single-arm forward spectrometer covering the pseudorapidity range of $2 < \\eta < 5$. The detector includes:\n",
        "\n",
        "- **Tracking system** - used for high-precision measurements of the momentum of charged particles and the position of the primary vertices\n",
        "- **Particle Identification (PID) system** - used to distiguish different species of traversing particles (i.e., muons, pions, kaons, protons)\n",
        "\n",
        "The LHCb PID system counts two ring-imaging Cherenkov ([RICH](https://lhcb-outreach.web.cern.ch/detector/rich-detectors/)) detectors whose response allows to separate different types of charged hadrons (e.g., pions, kaons, protons) using the [Cherenkov radiation](https://en.wikipedia.org/wiki/Cherenkov_radiation) of the traversing particles."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5If4oPxki5xK"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/mbarbetti/pidgan-notebooks/main/.github/images/lhcb.jpeg\" width=\"800\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPnfIVMoi5xK"
      },
      "source": [
        "### What are GANs?\n",
        "\n",
        "Generative Adversarial Networks [[1](https://arxiv.org/abs/1406.2661)] are a powerful class of _generative models_ based on the simultaneous training of two neural networks:\n",
        "\n",
        "*  **Discriminator network** ($D$) - trained by a classification task to separate the generator output from the reference dataset\n",
        "* **Generator network** ($G$) - trained by a simulation task to reproduce the reference dataset trying to fake the discriminator\n",
        "\n",
        "The goal is that $D$ optimally discriminates on the origin of the two samples, and simultaneously the training procedure for $G$ is to maximize the _probability_ of $D$ making a mistake. This framework corresponds to a **minimax two-player game** [[1](https://arxiv.org/abs/1406.2661)]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_Hs8F8pi5xK"
      },
      "source": [
        "<div align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/mbarbetti/pidgan-notebooks/main/.github/images/gan-scheme.png\" width=\"800\"/>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmUghh5Ii5xK"
      },
      "source": [
        "#### Mathematical details\n",
        "\n",
        "The generator $G(z)$, fed by elements $z$ sampled according to a known distribution $p_z$ (typically gaussian), maps the **latent space** $\\mathcal{Z}$ to the reference dataset $\\mathcal{X}$, inducing a distribution $p_\\rm{gen}$ trained to match with the target distribution $p_\\rm{ref}$. The discriminator $D(x)$ outputs a single scalar, readable as the **probability** that $x$ comes from the reference dataset rather than $G$. Hence, the optimization problem corresponds to train $D$ to maximize the probability of correct labelling, and simultaneously training $G$ to minimize $\\log(1 - D(G(z)))$.\n",
        "\n",
        "Defining the **loss function** $\\mathcal{L}_{\\rm{GAN}}$ as follows\n",
        "\n",
        "<center>$\\mathcal{L}_{\\rm{GAN}} (\\theta_d, \\theta_g) = \\mathbb{E}_{x \\sim p_\\rm{ref}} \\left[ \\log{D_{\\theta_d}(x)} \\right] + \\mathbb{E}_{z \\sim p_\\rm{z}} \\left[ \\log(1 - D_{\\theta_d}(G_{\\theta_g}(z))) \\right]$</center>\n",
        "\n",
        "the _minimax game_ can be written in this form:\n",
        "\n",
        "<center>$\\displaystyle{\\min_G \\, \\max_D \\, \\mathcal{L}_{\\rm{GAN}} (\\theta_d, \\theta_g)}$</center>\n",
        "\n",
        "A unique solution exists, with $G$ recovering the reference distribution $p_\\rm{ref}$ and $D$ equal to 1/2 everywhere [[1](https://arxiv.org/abs/1406.2661)].\n",
        "\n",
        "Traditional GAN systems suffer from many issues, particularly during the training phase:\n",
        "\n",
        "* the generator _may collapse_ producing only a single sample or a small family of very similar samples (**mode collapse**)\n",
        "* the two players _may oscillate_ during training rather than converging to the [**Nash equilibrium**](https://en.wikipedia.org/wiki/Nash_equilibrium)\n",
        "* if _imbalance_ between the two players occurs, then the system is incapable of learning at all\n",
        "\n",
        "All these drawbacks result from the [**vanishing gradient problem**](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), namely the lack of information for the update of the $G$ parameters. This is due to the saturation of the $D$ that is so good in distinguishing the origin of the two samples that no errors remain to the $G$ to improve the generated space. To fix the problem, one can add _continuous noise_ to both $D$ and $G$. This trick allows to learn thanks to a non-zero gradient [[2](https://arxiv.org/abs/1701.04862)]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnwMxPJUi5xK"
      },
      "source": [
        "#### Using input conditions\n",
        "\n",
        "Feeding the generator with additional information besides the latent space sample allows to **conditionate** its output. In particular, it's sufficient to concatenate the conditional features $x$ to the random noise $z$ passed as input to $G$ to make it able to take into account this information [[3](https://arxiv.org/abs/1411.1784)]: $y_{\\rm{gen}}(x) = G(x, z)$. Obviously, to preserve the capability to learn through the minimax game, also the discriminator must be fed by the additional features $x$, simply concatenating them to either elements of the reference sample or of the generated space [[3](https://arxiv.org/abs/1411.1784)]: $D(x, y)$ with $y \\in \\{y_{\\rm{ref}}, y_{\\rm{gen}}\\}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvpIdCnSi5xL"
      },
      "source": [
        "## Tutorial\n",
        "\n",
        "The aim of this tutorial is to build a parameterization of the LHCb RICH detectors. Since we expect that the high-level response of the RICH system only depends on the kinematics of the traversing particles and the detector occupancy, the former can be parameterized training a **GAN model** properly conditioned [[3](https://arxiv.org/abs/1411.1784), [4](https://arxiv.org/abs/1905.11825)]. The pidgan package provides several GAN [`algorithms`](https://github.com/mbarbetti/pidgan/tree/main/src/pidgan/algorithms) implementing some of the most used tricks presented in the literature to stablize their training [[1](https://arxiv.org/abs/1406.2661), [2](https://arxiv.org/abs/1701.04862), [5](https://arxiv.org/abs/1606.03498)]. The pidgan's [`players`](https://github.com/mbarbetti/pidgan/tree/main/src/pidgan/players), namely the generator and discriminator network, are designed to be trained taking conditions as input. In this notebook we will see how to build a model for the RICH system using the pidgan's [`GAN`](https://github.com/mbarbetti/pidgan/blob/main/src/pidgan/algorithms/GAN.py) algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ohrh3dQi5xL"
      },
      "source": [
        "### Install\n",
        "\n",
        "The first step is to install the [pidgan](https://github.com/mbarbetti/pidgan) package and some other ones that are typically needed in machine learning applications to High Energy Physics (i.e., uproot, scipy, scikit-learn, matplotlib)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r8glZROOi5xL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pidgan[lamarr]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmb7g7HZi5xL"
      },
      "source": [
        "Now, let's verify the correct installation of pidgan printing its version:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CWg67WFhi5xL",
        "outputId": "104a83e9-abfc-422e-98e9-3f9ddb59f284",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.0.5'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pidgan\n",
        "\n",
        "pidgan.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8lt6bjDi5xM"
      },
      "source": [
        "In case you're running this notebook on a machine equipped with a GPU, let's also verify the correct installation of TensorFlow:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xGoxRYbGi5xM",
        "outputId": "4085da54-47dd-4004-e6e2-139bc4605c3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.config.list_physical_devices(\"GPU\")  # outputs a non-empty list in case of GPU equipped"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we just have to import all the modules that we will use in the following code cells:"
      ],
      "metadata": {
        "id": "Uslhx_PjvOwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "import uproot\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.utils import shuffle"
      ],
      "metadata": {
        "id": "twM1ba1PvgVl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data loading"
      ],
      "metadata": {
        "id": "Cz9PhSN8wP2h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDfCdUkIi5xM"
      },
      "source": [
        "### Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVNTdWLPi5xM"
      },
      "source": [
        "### Model definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0htLzsSri5xM"
      },
      "source": [
        "### Training procedure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hdn_BRai5xM"
      },
      "source": [
        "### Validation plots"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model export"
      ],
      "metadata": {
        "id": "jOYaaPWMnJXD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKqBzg-Fi5xM"
      },
      "source": [
        "## References\n",
        "\n",
        "1. I.J. Goodfellow _et al._, \"Generative Adversarial Networks\", [arXiv:1406.2661](https://arxiv.org/abs/1406.2661)\n",
        "2. M. Arjovsky, L. Bottou, \"Towards Principled Methods for Training Generative Adversarial Networks\", [arXiv:1701.04862](https://arxiv.org/abs/1701.04862)\n",
        "3. M. Mirza, S. Osindero, \"Conditional Generative Adversarial Nets\", [arXiv:1411.1784](https://arxiv.org/abs/1411.1784)\n",
        "4. A. Maevskiy _et al._, \"Fast Data-Driven Simulation of Cherenkov Detectors Using Generative Adversarial Networks\", [arXiv:1905.11825](https://arxiv.org/abs/1905.11825)\n",
        "5. T. Salimans _et al._, \"Improved Techniques for Training GANs\", [arXiv:1606.03498](https://arxiv.org/abs/1606.03498)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f26wCo4i5xN"
      },
      "source": [
        "## Credits\n",
        "This tutorial is based on the notebooks provided by the [mbarbetti/tf-gen-models](https://github.com/mbarbetti/tf-gen-models) repository."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf213",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}